{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7a3af-7d82-4bac-9288-1448962ac389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For visualisation\n",
    "!pip install denku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da2406-8823-42c3-a75b-e111b6d7143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from diffusers.utils import load_video, export_to_video\n",
    "from diffusers import AutoencoderKLWan, FlowMatchEulerDiscreteScheduler, UniPCMultistepScheduler\n",
    "from transformers import UMT5EncoderModel, T5TokenizerFast\n",
    "from controlnet_aux import HEDdetector, CannyDetector, MidasDetector\n",
    "from denku import show_images\n",
    "\n",
    "from wan_controlnet import WanControlnet\n",
    "from wan_transformer import CustomWanTransformer3DModel\n",
    "from wan_t2v_controlnet_pipeline import WanTextToVideoControlnetPipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac6c2d-fe25-4e1d-9d66-3e0083818097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wan-AI/Wan2.2-TI2V-5B-Diffusers\n",
    "base_model_path = \"Wan-AI/Wan2.2-TI2V-5B-Diffusers\"\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(base_model_path, subfolder=\"tokenizer\")\n",
    "text_encoder = UMT5EncoderModel.from_pretrained(base_model_path, subfolder=\"text_encoder\", torch_dtype=torch.bfloat16)\n",
    "vae = AutoencoderKLWan.from_pretrained(base_model_path, subfolder=\"vae\", torch_dtype=torch.float32)\n",
    "transformer = CustomWanTransformer3DModel.from_pretrained(base_model_path, subfolder=\"transformer\", torch_dtype=torch.bfloat16)\n",
    "scheduler = FlowMatchEulerDiscreteScheduler.from_pretrained(base_model_path, subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0451e1-6fab-43cb-9c3d-e5c613b1dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TheDenk/wan2.2-ti2v-5b-controlnet-depth-v1\n",
    "controlnet_model_path = \"TheDenk/wan2.2-ti2v-5b-controlnet-depth-v1\"\n",
    "\n",
    "controlnet = WanControlnet.from_pretrained(controlnet_model_path, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facb7e7-bc91-4c07-a079-b05f942921f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = WanTextToVideoControlnetPipeline.from_pretrained(\n",
    "    pretrained_model_name_or_path=base_model_path,\n",
    "    tokenizer=tokenizer, \n",
    "    text_encoder=text_encoder,\n",
    "    transformer=transformer,\n",
    "    vae=vae, \n",
    "    controlnet=controlnet,\n",
    "    scheduler=scheduler,\n",
    ")\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config, flow_shift=5.0)\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5447ff9c-e9c4-4910-aabb-d53d2f0d718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_controlnet(controlnet_type, device='cuda'):\n",
    "    if controlnet_type in ['canny']:\n",
    "        return controlnet_mapping[controlnet_type]()\n",
    "    return controlnet_mapping[controlnet_type].from_pretrained('lllyasviel/Annotators').to(device=device)\n",
    "\n",
    "controlnet_mapping = {\n",
    "    'canny': CannyDetector,\n",
    "    'hed': HEDdetector,\n",
    "    'depth': MidasDetector,\n",
    "}\n",
    "controlnet_processor = init_controlnet(\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a7c90-cedf-4121-93ce-bef7aca80875",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = 704 # 704 480\n",
    "img_w = 1280 # 1280 832\n",
    "num_frames = 121  # 121 81 49\n",
    "\n",
    "video_path = '../resources/bubble.mp4'\n",
    "video_frames = load_video(video_path)[:num_frames]\n",
    "video_frames = [x.resize((img_w, img_h)) for x in video_frames]\n",
    "controlnet_frames = [controlnet_processor(x) for x in video_frames]\n",
    "\n",
    "show_images(video_frames[::25], figsize=(16, 8))\n",
    "show_images(controlnet_frames[::25], figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6286ea9-89e2-4834-b4f6-ac790138de1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"Close-up shot with soft lighting, focusing sharply on the lower half of a young woman's face. Her lips are slightly parted as she blows an enormous bubblegum bubble. The bubble is semi-transparent, shimmering gently under the light, and surprisingly contains a miniature aquarium inside, where two orange-and-white goldfish slowly swim, their fins delicately fluttering as if in an aquatic universe. The background is a pure light blue color.\"\n",
    "negative_prompt = \"bad quality, worst quality\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    height=img_h,\n",
    "    width=img_w,\n",
    "    num_frames=num_frames,\n",
    "    guidance_scale=5,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    "    output_type=\"pil\",\n",
    "\n",
    "    controlnet_frames=controlnet_frames,\n",
    "    controlnet_guidance_start=0.0,\n",
    "    controlnet_guidance_end=0.8,\n",
    "    controlnet_weight=0.8,\n",
    "\n",
    "    teacache_treshold=0.6,\n",
    ").frames[0]\n",
    "\n",
    "show_images(output[:2], figsize=(6, 12))\n",
    "export_to_video(output, \"output.mp4\", fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9ea5f-f896-4c2c-8418-88d9a6860c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
